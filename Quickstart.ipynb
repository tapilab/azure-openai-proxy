{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4963b3f0-b602-48d0-9155-bbe5c3cc92a8",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "\n",
    "Examples using the Azure Function proxy to call LLMs in the private cloud.\n",
    "\n",
    "1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113599fa-e342-496a-b279-ca739322199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai python-dotenv dspy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601e0af-8a73-4708-9bdd-1b7e0c4e31cb",
   "metadata": {},
   "source": [
    "2. Create .env file\n",
    "\n",
    "Create a file named .env in your project folder:\n",
    "\n",
    "```\n",
    "# Base URL of the proxy (must end with /api/v1)\n",
    "PROXY_BASE_URL=https://<your-function-app>.azurewebsites.net/api/v1\n",
    "\n",
    "# Shared host key (treat like a password)\n",
    "FUNCTION_HOST_KEY=<paste-the-shared-host-key-here>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf5c43c-c66a-4388-9f21-a858dd36c79c",
   "metadata": {},
   "source": [
    "### Example: OpenAI Responses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f1d3419-d43c-4f9e-a886-5179ddafd29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beneath the faint glow of the moon, the lost letter finally found its way home, reuniting two souls who had always been meant to cross paths.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "base_url = os.environ[\"PROXY_BASE_URL\"].rstrip(\"/\")\n",
    "fn_key = os.environ[\"FUNCTION_HOST_KEY\"]\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=\"unused\",  # required by SDK; auth is via x-functions-key\n",
    "    default_headers={\"x-functions-key\": fn_key},\n",
    ")\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"Tell me a one line story.\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe8b372-5366-4adb-bcdf-3d7efb0baf94",
   "metadata": {},
   "source": [
    "### Example: DSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39f0cefa-a9ab-4520-b661-a9c8cce024d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As the clock struck midnight, she finally opened the letter that would change her life forever.\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "lm = dspy.LM(\n",
    "    \"openai/gpt-4o-mini\",\n",
    "    api_base=base_url,\n",
    "    api_key=\"unused\",  # required by OpenAI/LiteLLM; proxy ignores it\n",
    "    extra_headers={\"x-functions-key\": fn_key},  # <-- the important part\n",
    ")\n",
    "\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "pred = dspy.Predict(\"question -> answer\")(question=\"Tell me a one line story.\")\n",
    "print(pred.answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
